### 这个项目是用于记录我对SNN的研究过程的，仅供参考，有兴趣的可以来探讨


#### V0.1版本：
（1） 我打算从细胞开始建起，每个细胞都有属于自己的电位与电位消散速度，同时细胞之间的连接也有权重控制，训练方法使用的是两种调整策略
    · 若细胞A对细胞B经常性地传递兴奋，则A对B的连接权重加大（单向的），即A对B传递的兴奋每次传递的量更多
    · 在输出端使用痛感刺激（即负反馈信号）来调整网络权重，类似于反向传播，每个时间帧，若输出端信号与标签不同，则对整个网络进行一次参数调整，这里我设想的是从输出端往回找，每次找到该时间帧兴奋了的神经元，其与其他神经元的连接权重进行百分比削减，同时其兴奋阈值提高，电信号消散速度加快，该策略的指导思想是：若输出端获得的信号不符合要求，则所有贡献过兴奋的神经元都得负责，即受到鞭策。
  在实现时，我发现如果按照当前时间帧来找可能会发生时间错位的问题，毕竟当前的输出可能是第一个神经元几个帧前兴奋造成的，而当前时间帧的兴奋影响的因该是几个帧后的输出（具体看细胞与输出端的距离而定）。

（2） 查看了官方文档后我发现，官方文档定义的参数实际上只有细胞之间的权重，而不是连兴奋电位和消散速度都会变的。

#### V0.2版本：
（1） 这几天我思考了一下我们对于现实世界东西的学习都是基于同时发生的刺激进行的
    · 比如我们第一次看到猫的同时，如果一直听到一种奇怪的叫声，那么我们就会将这种声音与猫联系起来，下次看到猫时脑子里就会响起那种声音。
    · 换个说法，我们每次吃话梅的时候，口水都会一直流，吃的次数多了，下次看到话梅时就会流口水
    · 再比如袁华的BGM，每次都有“一剪梅”伴随他出场，下次看到袁华，BGM就在脑子里响起了。
    
（2）这与STDP更新方法似乎有一定的联系，STDP的方法是，如果一个神经元A给B发送信号后一段时间内，B也兴奋了，则A与B的权重会升高，若B在A发送信号前的一段时间内就已经兴奋过了，则A与B的联系减弱。
    · 我们可以设想一种情况，比如吃话梅，我们眼睛看到话梅后视觉端的神经元A发送信号给中枢神经元C，同时味觉细胞B也给C发送信号，在一小段时间后，C被激活，给唾液腺细胞D发送兴奋，然后分泌唾液。
    · 这一轮下来，A对C的权重大大增强（B对C也一样），下次看到话梅时，不用B的电信号加持，仅仅一个A就可以直接激活C，然后C给D发送信号，D兴奋，口腔分泌唾液。

（3）换个思路，现在我打算完成一个手写字识别，我从视觉A端输入手写字的图片，然后从B端输入label，同时设置一个谜之输出端D（我也不知道会输出什么），然后不断从A端输入图片同时B端传入label，一直训练，其实不一定要有D端，通过一直这样训练（使用STDP方法更新权重），我们可以肯定，当我们输入某一张图片时，该图片与对应label曾经共同激活过的某个C端被激活了，但是D端与C端并没有什么固定联系。问题所在便是：我们的基因设定好的，一旦感到酸就会分泌唾液，这就是C端和D端的联系，但在上面这个例子中，我们找不到。

~~（4）有一种方法可以强行建立两个的联系--痛觉。假设一只猫来到一个藏有刺的地毯上，但它没发现，它只感觉莫名奇妙一阵刺痛，然后它就跑了，如果次数一多，它下次看到地毯就会跑路，这里，地毯与跑路这个行为并没有直接联系。~~
（4）这里更正一下痛觉相关的内容，经过几天的思考，我发现痛觉也是一种感觉，我们通过神经元感觉到疼痛，抑制我们的行为。一只猫看见了火苗（神经元A传入视觉信息），好奇地去触碰（神经元D输出信号），感到了剧烈疼痛（神经元B传入痛觉信息），此时会直接收手（这里有先天本能的作用），此外，持续的灼伤感会加深我们对火与痛觉之间的联系（共同作用于痛觉神经元C），此后，猫看见火苗就会想起当初的疼痛（神经元A的输入神经元C被激活），对于“伸手去碰”（即神经元D的输出）这一件事的倾向就会大大缩减，这代表C对D传输的信号是抑制的，痛觉对我们的行为有一种抑制的作用（具体对什么行为进行抑制似乎是由基因决定的），但我目前还没想明白这个抑制策略，即C如何准确找到应该抑制哪一个神经元。
PS：痛觉是一个很复杂的过程，似乎并不像唾液分泌那么简单，这个过程还有待研究。

（5）这一版本的网络采用了统一的激活电位与电位消散速度，权重仅有细胞突触间的权重，同时使用了一个新的训练策略，即我们不使用传统的方法：模型获取input经过一系列计算之后获得输出，然后与label作比较。我们采用新的策略：模型具有三个端（A，B，D端），从A，B端传入input与Label，然后从D端等待输出。这一思路的问题就是我暂时还没找到较为合适的训练策略，如何建立起D端输出与label的联系。（在这一思路中，网络中隐藏了未知的C端，而对于生物来讲，基因的编码使得未知的C端可以明确地建立与输出端D端的联系，但对于我们来说我们没办法这么干）。


#### v0.3版本
（1）由于短时间内无法找到从隐藏神经元到输出端的有效反馈训练，我将目光转移到了反向传播上，我尝试用torch构建一个图网络进行训练，并使用反向传播来进行。
（2）对于构造这个图的计算过程，我遵循如下思路：
    1. 这里假定某个脑域内所有神经元细胞构成一个全连接图，其神经元总数为n，则使用一个n*n全连接矩阵net保存神经元间的连接权重，同时有一个1*n的向量node_val记录着细胞当前时刻的电位
    2. 每个时间帧，细胞的电位都会有所下降，这里采用指数下降的方式，即node_val = node_val * level_descrease
    3. 随后从该图的输入节点处传入前面网络的信息（比如来自眼睛的图片信息），此时图中部分节点的电位水平增加，即node_val某些维度电位水平上升。
    4. node_val电位到达1的细胞进行激活，其电位水平下降至-0.1，同时其激活的细胞被记录为 node_activate，这时一个bool mask，维度与node_val一致。
    5. 被激活的node_val会向其他细胞发送信息大小为1的电信号，但是会受到与其他神经元连接权重的控制，发送结果记录在node_out向量中：
                node_out = torch.sum(net * active_node_val, dim=1, keepdim=True).reshape(batch_size,-1,1)
    6. node_out是一个维度与node_val一致的向量，其记录着每个神经元下个时间帧收到的来自该脑域其他神经元的电信号，node_val+node_out即为下个时间帧每个神经元的电位值
    7. 重复3~6步直到到达所要求的时间帧数目，期间从输出神经元处便不断产生电信号，将其累计起来，便可作为该脑域的输出





